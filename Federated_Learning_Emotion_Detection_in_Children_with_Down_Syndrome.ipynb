{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bx8NRAxA8Lf",
        "outputId": "eba3371e-eaed-4e43-8e71-55a80a964f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu May 23 11:59:27 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1pW6NQJAiuxN"
      },
      "outputs": [],
      "source": [
        "# pip install --upgrade tensorflow-federated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I29qcdeCBIZM",
        "outputId": "b27f4d90-f79c-49f8-fc97-dce083ab01a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y36eJKJBBLMq"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/ultralytics/yolov5\n",
        "# %cd yolov5\n",
        "# !pip install -r requirements.txt -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzQkgKyaChG2",
        "outputId": "874ee5b6-6c85-4d9c-e520-81b434cc663d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/74.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.9/74.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q roboflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A_pdQHybC-Np"
      },
      "outputs": [],
      "source": [
        "picture_size = 640\n",
        "folder_path = \"/content/Down-Syndrome-FER-1/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2qneZoMA8ym",
        "outputId": "bf8b9136-bdf3-4de0-bf54-ebae0df51fe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: roboflow in /usr/local/lib/python3.10/dist-packages (1.1.29)\n",
            "Requirement already satisfied: certifi==2023.7.22 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2023.7.22)\n",
            "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.0.0)\n",
            "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.10.0)\n",
            "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.10)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.25.2)\n",
            "Requirement already satisfied: opencv-python-headless==4.8.0.74 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.8.0.74)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.0.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from roboflow) (0.4.27)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.51.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in Down-Syndrome-FER-1 to multiclass:: 100%|██████████| 658688/658688 [00:26<00:00, 24680.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Down-Syndrome-FER-1 in multiclass:: 100%|██████████| 24052/24052 [00:09<00:00, 2454.32it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"gP5AwrgZJgUcW0SKKqG2\")\n",
        "project = rf.workspace(\"ferdownsyndrome\").project(\"down-syndrome-fer\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"multiclass\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nALMw-TBCkAr",
        "outputId": "5276d9d0-d065-48c9-cd6a-186db8ce3dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Down-Syndrome-FER-1\n"
          ]
        }
      ],
      "source": [
        "%cd Down-Syndrome-FER-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AtS39GfoDaqZ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "import shutil\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import Model,Sequential\n",
        "from keras.optimizers import Adam,SGD,RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Zk3A0CmIKwLn"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/Down-Syndrome-FER-1/test/_classes.csv')\n",
        "output_dir = '/content/Down-Syndrome-FER-1/test/'\n",
        "for col in df.columns[1:]:\n",
        "    class_dir = os.path.join(output_dir, col)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']\n",
        "    for col in df.columns[1:]:\n",
        "        class_value = row[col]\n",
        "        class_dir = os.path.join(output_dir, col)\n",
        "        if class_value == 1:\n",
        "            src_path = os.path.join('/content/Down-Syndrome-FER-1/test', filename)\n",
        "            dest_path = os.path.join(class_dir, filename)\n",
        "            if os.path.exists(src_path):\n",
        "                shutil.move(src_path, dest_path)\n",
        "                # print(\"File f\")\n",
        "            else:\n",
        "                continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2bslHaFUKor8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "df = pd.read_csv('/content/Down-Syndrome-FER-1/train/_classes.csv')\n",
        "output_dir = '/content/Down-Syndrome-FER-1/train/'\n",
        "for col in df.columns[1:]:\n",
        "    class_dir = os.path.join(output_dir, col)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']\n",
        "    for col in df.columns[1:]:\n",
        "        class_value = row[col]\n",
        "        class_dir = os.path.join(output_dir, col)\n",
        "        if class_value == 1:\n",
        "            src_path = os.path.join('/content/Down-Syndrome-FER-1/train', filename)\n",
        "            dest_path = os.path.join(class_dir, filename)\n",
        "            if os.path.exists(src_path):\n",
        "                shutil.move(src_path, dest_path)\n",
        "            else:\n",
        "                continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RYW0PgoDKmN6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "df = pd.read_csv('/content/Down-Syndrome-FER-1/valid/_classes.csv')\n",
        "output_dir = '/content/Down-Syndrome-FER-1/valid/'\n",
        "for col in df.columns[1:]:\n",
        "    class_dir = os.path.join(output_dir, col)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "for index, row in df.iterrows():\n",
        "    filename = row['filename']\n",
        "    for col in df.columns[1:]:\n",
        "        class_value = row[col]\n",
        "        class_dir = os.path.join(output_dir, col)\n",
        "        if class_value == 1:\n",
        "            src_path = os.path.join('/content/Down-Syndrome-FER-1/valid', filename)\n",
        "            dest_path = os.path.join(class_dir, filename)\n",
        "            if os.path.exists(src_path):\n",
        "                shutil.move(src_path, dest_path)\n",
        "            else:\n",
        "                continue\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vUBSb4PzDIPT"
      },
      "outputs": [],
      "source": [
        "# expression = 'dislike'\n",
        "\n",
        "# plt.figure(figsize= (12,12))\n",
        "# for i in range(1, 10, 1):\n",
        "#     plt.subplot(3,3,i)\n",
        "#     img = load_img(folder_path+\"train/\"+expression+\"/\"+os.listdir(folder_path + \"train/ \" +expression)[i], target_size=(picture_size, picture_size))\n",
        "#     plt.imshow(img)\n",
        "# plt.show()\n",
        "\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "\n",
        "expression = ' dislike'\n",
        "picture_size = 128\n",
        "\n",
        "plt.figure(figsize=(12, 12))\n",
        "file_list = os.listdir(f\"{folder_path}/train/ {expression}/\")\n",
        "file_list = [file for file in file_list if file.endswith('.jpg')][:100]\n",
        "\n",
        "print(file_list)\n",
        "\n",
        "for i, file in enumerate(file_list, 1):\n",
        "    plt.subplot(3, 3, i)\n",
        "    img = load_img(f\"{folder_path}/train/ {expression}/{file}\", target_size=(picture_size, picture_size))\n",
        "    plt.imshow(img)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# img = load_img('/content/Down-Syndrome-FER-1/train/ dislike/10008_jpg.rf.0626c057b82f695a25f5d3b5da0ca009.jpg')\n",
        "# plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WIMsFt3EFCK",
        "outputId": "3c9e5486-e235-4b5b-ee33-8c459a59a6d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21536 images belonging to 4 classes.\n",
            "Found 2389 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size  = 128\n",
        "\n",
        "datagen_train  = ImageDataGenerator()\n",
        "datagen_val = ImageDataGenerator()\n",
        "\n",
        "train_set = datagen_train.flow_from_directory(folder_path+\"train\",\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=True)\n",
        "\n",
        "\n",
        "test_set = datagen_val.flow_from_directory(folder_path+\"test\",\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=False)\n",
        "\n",
        "valid_set = datagen_val.flow_from_directory(folder_path+\"valid\",\n",
        "                                              target_size = (picture_size,picture_size),\n",
        "                                              color_mode = \"grayscale\",\n",
        "                                              batch_size=batch_size,\n",
        "                                              class_mode='categorical',\n",
        "                                              shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "W55Cy6y-F63m"
      },
      "outputs": [],
      "source": [
        "from keras.regularizers import l2\n",
        "from keras.models import Model\n",
        "from keras import layers\n",
        "from keras.layers import Activation, Convolution2D, Conv2D, Dropout, AveragePooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Input, MaxPooling2D, SeparableConv2D\n",
        "batch_size = 32\n",
        "epochs = 40\n",
        "image_shape = (640,640,2)\n",
        "verbose = True\n",
        "num_class = 4\n",
        "patience = 5  # number of epochs with no improvement after which training will be stopped\n",
        "base_path = './'\n",
        "l2_regularization = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h_6ZSiJxF8TD"
      },
      "outputs": [],
      "source": [
        "# model\n",
        "regularization = l2(l2_regularization)\n",
        "image_shape = (640,640,3)\n",
        "image_input = Input(image_shape)\n",
        "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(image_input)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = Conv2D(filters=8, kernel_size=(3,3), strides=(1,1), kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "# module 1\n",
        "# residual module\n",
        "residual = Conv2D(filters=16, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(filters=16, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
        "x = layers.add([x,residual])\n",
        "\n",
        "# module 2\n",
        "# residual module\n",
        "residual = Conv2D(filters=32, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(filters=32, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
        "x = layers.add([x,residual])\n",
        "\n",
        "# module 3\n",
        "# residual module\n",
        "residual = Conv2D(filters=64, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(filters=64, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
        "x = layers.add([x,residual])\n",
        "\n",
        "# module 4\n",
        "# residual module\n",
        "residual = Conv2D(filters=128, kernel_size=(1,1), strides=(2,2), padding='same', use_bias=False)(x)\n",
        "residual = BatchNormalization()(residual)\n",
        "\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = SeparableConv2D(filters=128, kernel_size=(3,3), padding='same', kernel_regularizer=regularization, use_bias=False)(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same')(x)\n",
        "x = layers.add([x,residual])\n",
        "\n",
        "x = Conv2D(filters=num_class, kernel_size=(3,3), padding='same')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "output = Activation('softmax', name='predictions')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jp97o78qF-Dg",
        "outputId": "186ba91c-4048-46f7-eb20-c28b90859c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 46, 46, 8)            72        ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization (Batch  (None, 46, 46, 8)            32        ['conv2d[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 46, 46, 8)            0         ['batch_normalization[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 44, 44, 8)            576       ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (Bat  (None, 44, 44, 8)            32        ['conv2d_1[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 44, 44, 8)            0         ['batch_normalization_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d (Separabl  (None, 44, 44, 16)           200       ['activation_1[0][0]']        \n",
            " eConv2D)                                                                                         \n",
            "                                                                                                  \n",
            " batch_normalization_3 (Bat  (None, 44, 44, 16)           64        ['separable_conv2d[0][0]']    \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 44, 44, 16)           0         ['batch_normalization_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_1 (Separa  (None, 44, 44, 16)           400       ['activation_2[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_4 (Bat  (None, 44, 44, 16)           64        ['separable_conv2d_1[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 22, 22, 16)           128       ['activation_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 22, 22, 16)           0         ['batch_normalization_4[0][0]'\n",
            " D)                                                                 ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (Bat  (None, 22, 22, 16)           64        ['conv2d_2[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 22, 22, 16)           0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'batch_normalization_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_2 (Separa  (None, 22, 22, 32)           656       ['add[0][0]']                 \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_6 (Bat  (None, 22, 22, 32)           128       ['separable_conv2d_2[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 22, 22, 32)           0         ['batch_normalization_6[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_3 (Separa  (None, 22, 22, 32)           1312      ['activation_3[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_7 (Bat  (None, 22, 22, 32)           128       ['separable_conv2d_3[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 11, 11, 32)           512       ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 11, 11, 32)           0         ['batch_normalization_7[0][0]'\n",
            " g2D)                                                               ]                             \n",
            "                                                                                                  \n",
            " batch_normalization_5 (Bat  (None, 11, 11, 32)           128       ['conv2d_3[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 11, 11, 32)           0         ['max_pooling2d_1[0][0]',     \n",
            "                                                                     'batch_normalization_5[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_4 (Separa  (None, 11, 11, 64)           2336      ['add_1[0][0]']               \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_9 (Bat  (None, 11, 11, 64)           256       ['separable_conv2d_4[0][0]']  \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 11, 11, 64)           0         ['batch_normalization_9[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_5 (Separa  (None, 11, 11, 64)           4672      ['activation_4[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_10 (Ba  (None, 11, 11, 64)           256       ['separable_conv2d_5[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 64)             2048      ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 64)             0         ['batch_normalization_10[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_8 (Bat  (None, 6, 6, 64)             256       ['conv2d_4[0][0]']            \n",
            " chNormalization)                                                                                 \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 6, 6, 64)             0         ['max_pooling2d_2[0][0]',     \n",
            "                                                                     'batch_normalization_8[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " separable_conv2d_6 (Separa  (None, 6, 6, 128)            8768      ['add_2[0][0]']               \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_12 (Ba  (None, 6, 6, 128)            512       ['separable_conv2d_6[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 6, 6, 128)            0         ['batch_normalization_12[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " separable_conv2d_7 (Separa  (None, 6, 6, 128)            17536     ['activation_5[0][0]']        \n",
            " bleConv2D)                                                                                       \n",
            "                                                                                                  \n",
            " batch_normalization_13 (Ba  (None, 6, 6, 128)            512       ['separable_conv2d_7[0][0]']  \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 128)            8192      ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 3, 3, 128)            0         ['batch_normalization_13[0][0]\n",
            " g2D)                                                               ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_11 (Ba  (None, 3, 3, 128)            512       ['conv2d_5[0][0]']            \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 3, 3, 128)            0         ['max_pooling2d_3[0][0]',     \n",
            "                                                                     'batch_normalization_11[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 3, 3, 4)              4612      ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " global_average_pooling2d (  (None, 4)                    0         ['conv2d_6[0][0]']            \n",
            " GlobalAveragePooling2D)                                                                          \n",
            "                                                                                                  \n",
            " predictions (Activation)    (None, 4)                    0         ['global_average_pooling2d[0][\n",
            "                                                                    0]']                          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 54964 (214.70 KB)\n",
            "Trainable params: 53492 (208.95 KB)\n",
            "Non-trainable params: 1472 (5.75 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Model(image_input, output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "V5ba2MQqF_Pd"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=patience)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=int(patience/4), verbose=verbose)\n",
        "\n",
        "trained_models_path = base_path + '_mini_xception'\n",
        "model_names = trained_models_path + 'model.hdf5'\n",
        "model_checkpoint = ModelCheckpoint(filepath=model_names, monitor='val_loss', verbose=verbose, save_best_only=True)\n",
        "\n",
        "callbacks = [model_checkpoint,  early_stop, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BmHFVaRKOLWn"
      },
      "outputs": [],
      "source": [
        "# !pip install --upgrade numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HLQrPmfsGAqF"
      },
      "outputs": [],
      "source": [
        "history = model.fit_generator(generator=train_set,\n",
        "                                steps_per_epoch=train_set.n//train_set.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = test_set,\n",
        "                                validation_steps = test_set.n//test_set.batch_size,\n",
        "                                callbacks=callbacks\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUOkSbZdPHQ6"
      },
      "outputs": [],
      "source": [
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.ylabel('Accuracy', fontsize=16)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tRLZ0VBWsAd"
      },
      "outputs": [],
      "source": [
        "final_val_accuracy = history.history['val_accuracy'][-1]\n",
        "print(f'Final Validation Accuracy: {final_val_accuracy:.1f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw8Vclx42jlr"
      },
      "source": [
        "# Mini - Xception with federated learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB3NnoZ8SeWF"
      },
      "source": [
        "### Data prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PbQ4MbafEHSt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# import tensorflow_federated as tff\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Image dimensions\n",
        "img_height, img_width = 640, 640\n",
        "input_size = (img_height, img_width, 3)\n",
        "\n",
        "# Paths to your data directories\n",
        "train_dir = '/content/Down-Syndrome-FER-1/train'\n",
        "test_dir = '/content/Down-Syndrome-FER-1/test'\n",
        "valid_dir = '/content/Down-Syndrome-FER-1/valid'\n",
        "\n",
        "# Emotion names (classes)\n",
        "emotion_names = [' surprise', ' calm', ' dislike', ' attention']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULpVMpHmFk7f"
      },
      "source": [
        "### Mini Xception Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t1oxXepoBe1p"
      },
      "outputs": [],
      "source": [
        "# Define the Mini-Xception model\n",
        "def mini_xception(input_shape=(640, 640, 3), num_classes=4):\n",
        "    input = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Entry flow\n",
        "    x = layers.Conv2D(8, (3, 3), strides=(1, 1), padding='same')(input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(8, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(16, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(16, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    # Middle flow\n",
        "    for i in range(3):\n",
        "        residual = x\n",
        "        x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        x = layers.Conv2D(128, (3, 3), padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.Activation('relu')(x)\n",
        "        residual = layers.Conv2D(128, (1, 1), padding='same')(residual)  # Adjust channels in residual connection\n",
        "        x = layers.add([x, residual])\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(input, output)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6UY0ws2YFs88",
        "outputId": "a7e07e44-76dc-4468-d92b-7afc5e057be6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21536 images belonging to 4 classes.\n",
            "Found 119 images belonging to 4 classes.\n",
            "Found 2389 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "img_height, img_width = 640, 640\n",
        "\n",
        "# Create image data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Batch size\n",
        "batch_size = 4\n",
        "\n",
        "# Create generator for training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Create generator for test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Create generator for validation data\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "def load_and_split_data(generator, num_clients=3):\n",
        "    data_batches = []\n",
        "    labels_batches = []\n",
        "    for _ in range(num_clients):\n",
        "        data_batch, labels_batch = next(generator)\n",
        "        data_batches.append(data_batch)\n",
        "        labels_batches.append(labels_batch)\n",
        "    return data_batches, labels_batches\n",
        "\n",
        "# Define the number of clients\n",
        "num_clients = 6\n",
        "\n",
        "# Load and split train data\n",
        "client_data, client_labels = load_and_split_data(train_generator, num_clients)\n",
        "\n",
        "# Load test and validation data\n",
        "test_data, test_labels = next(test_generator)\n",
        "valid_data, valid_labels = next(valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dVFwK3oIIgXg"
      },
      "outputs": [],
      "source": [
        "# def load_and_split_data(generator, num_clients=3):\n",
        "#     data_batches = []\n",
        "#     labels_batches = []\n",
        "#     for _ in range(num_clients):\n",
        "#         data_batch, labels_batch = next(generator)\n",
        "#         data_batches.append(data_batch)\n",
        "#         labels_batches.append(labels_batch)\n",
        "#     return data_batches, labels_batches\n",
        "\n",
        "# # Define the number of clients\n",
        "# num_clients = 6\n",
        "\n",
        "# # Load and split train data\n",
        "# client_data_batches, client_labels_batches = load_and_split_data(train_generator, num_clients)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFQGo8IlIx9Y"
      },
      "source": [
        "### Federated Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uesoI9CGxEB",
        "outputId": "f4543b08-bc36-4249-f3cd-4ed12d60f27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "Training on client 1\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.5304 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.5604 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.9616 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.6005 - accuracy: 0.7500\n",
            "Training on client 2\n",
            "1/1 [==============================] - 9s 9s/step - loss: 2.2753 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.7248 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.4437 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0248 - accuracy: 1.0000\n",
            "Training on client 3\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.2272 - accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.3280 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.1896 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0199 - accuracy: 1.0000\n",
            "Training on client 4\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.1157 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.1784 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0258 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Training on client 5\n",
            "1/1 [==============================] - 8s 8s/step - loss: 2.0728 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.5076 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.2029 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0699 - accuracy: 1.0000\n",
            "Training on client 6\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.5067 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.2890 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.2473 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0262 - accuracy: 1.0000\n",
            "598/598 [==============================] - 26s 43ms/step - loss: 1.3757 - accuracy: 0.2491\n",
            "Validation loss: 1.3756558895111084, Validation accuracy: 0.24905818700790405\n",
            "Epoch 2/4\n",
            "Training on client 1\n",
            "1/1 [==============================] - 9s 9s/step - loss: 2.4640 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.3942 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.1470 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0907 - accuracy: 1.0000\n",
            "Training on client 2\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.3586 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 1.0302 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1355 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0392 - accuracy: 1.0000\n",
            "Training on client 3\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.8981 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0605 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0134 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Training on client 4\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.9286 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.1467 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Training on client 5\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.3476 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.4121 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2803 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0536 - accuracy: 1.0000\n",
            "Training on client 6\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.8253 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.6886 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0140 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "598/598 [==============================] - 23s 39ms/step - loss: 1.3910 - accuracy: 0.2231\n",
            "Validation loss: 1.3910412788391113, Validation accuracy: 0.22310590744018555\n",
            "Epoch 3/4\n",
            "Training on client 1\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.6220 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.3187 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.2971 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0832 - accuracy: 1.0000\n",
            "Training on client 2\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.5914 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.2081 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0234 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0149 - accuracy: 1.0000\n",
            "Training on client 3\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4055 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.2343 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0102 - accuracy: 1.0000\n",
            "Training on client 4\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.3945 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.7742 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0594 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0397 - accuracy: 1.0000\n",
            "Training on client 5\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.4987 - accuracy: 0.2500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.2638 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0974 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0383 - accuracy: 1.0000\n",
            "Training on client 6\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.9670 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0471 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "598/598 [==============================] - 24s 40ms/step - loss: 1.3741 - accuracy: 0.2231\n",
            "Validation loss: 1.374054193496704, Validation accuracy: 0.22310590744018555\n",
            "Epoch 4/4\n",
            "Training on client 1\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.5926 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.2293 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.1885 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0922 - accuracy: 1.0000\n",
            "Training on client 2\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.6327 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0171 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Training on client 3\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.7076 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.1483 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0081 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Training on client 4\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.8533 - accuracy: 0.7500\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0257 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0097 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Training on client 5\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.8220 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.1268 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.1033 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0270 - accuracy: 1.0000\n",
            "Training on client 6\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.0252 - accuracy: 0.5000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0462 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0104 - accuracy: 1.0000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0076 - accuracy: 1.0000\n",
            "598/598 [==============================] - 24s 40ms/step - loss: 1.4595 - accuracy: 0.2231\n",
            "Validation loss: 1.4594786167144775, Validation accuracy: 0.22310590744018555\n",
            "30/30 [==============================] - 2s 76ms/step - loss: 1.4643 - accuracy: 0.2353\n",
            "Test loss: 1.4642747640609741, Test accuracy: 0.23529411852359772\n"
          ]
        }
      ],
      "source": [
        "def aggregate_weights(weights):\n",
        "    \"\"\"Aggregate the weights from multiple models.\"\"\"\n",
        "    new_weights = []\n",
        "    for weights_list_tuple in zip(*weights):\n",
        "        new_weights.append(np.mean(weights_list_tuple, axis=0))\n",
        "    return new_weights\n",
        "\n",
        "# Create and compile the global model\n",
        "global_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(emotion_names))\n",
        "global_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Training loop\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "\n",
        "    client_weights = []\n",
        "\n",
        "    for client_idx in range(num_clients):\n",
        "        print(f'Training on client {client_idx + 1}')\n",
        "\n",
        "        # Create and compile a new model for the client\n",
        "        client_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(emotion_names))\n",
        "        client_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # Set the client model weights to the global model weights\n",
        "        client_model.set_weights(global_model.get_weights())\n",
        "\n",
        "        # Train the client model\n",
        "        for _ in range(4):  # Run 4 epochs for each client\n",
        "            client_model.fit(client_data[client_idx], client_labels[client_idx], epochs=1, verbose=1)\n",
        "\n",
        "        # Collect the client model weights\n",
        "        client_weights.append(client_model.get_weights())\n",
        "\n",
        "    # Aggregate the client model weights and update the global model\n",
        "    new_weights = aggregate_weights(client_weights)\n",
        "    global_model.set_weights(new_weights)\n",
        "\n",
        "    # Evaluate the global model on the validation data\n",
        "    val_loss, val_acc = global_model.evaluate(valid_generator, verbose=1)\n",
        "    print(f'Validation loss: {val_loss}, Validation accuracy: {val_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNDaTNR5OJi4",
        "outputId": "04b74686-ebf3-469d-9a01-80e9273163d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30 [==============================] - 1s 39ms/step - loss: 1.4643 - accuracy: 0.2353\n",
            "Test loss: -0.4642747640609741, Test accuracy: 0.7647058814764023\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the final global model on the test data\n",
        "test_loss, test_acc = global_model.evaluate(test_generator, verbose=1)\n",
        "print(f'Test loss: {1-test_loss}, Test accuracy: {1-test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uTa1PMhSlHB"
      },
      "source": [
        "# Ignore this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quUbrwHuOQQj"
      },
      "source": [
        "### trying to make it better (did not get better [actually did.. went from 23 to 26]) but loss increased as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dl4_CjKORtn",
        "outputId": "e02628d3-d0d4-4a8f-fcdf-914903af9e5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 21536 images belonging to 4 classes.\n",
            "Found 119 images belonging to 4 classes.\n",
            "Found 2389 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "img_height, img_width = 640, 640\n",
        "\n",
        "# Batch size\n",
        "batch_size = 4\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "def load_and_split_data(generator, num_clients=3):\n",
        "    data_batches = []\n",
        "    labels_batches = []\n",
        "    for _ in range(num_clients):\n",
        "        data_batch, labels_batch = next(generator)\n",
        "        data_batches.append(data_batch)\n",
        "        labels_batches.append(labels_batch)\n",
        "    return data_batches, labels_batches\n",
        "\n",
        "# Define the number of clients\n",
        "num_clients = 3\n",
        "\n",
        "# Load and split train data\n",
        "client_data, client_labels = load_and_split_data(train_generator, num_clients)\n",
        "\n",
        "# Load test and validation data\n",
        "test_data, test_labels = next(test_generator)\n",
        "valid_data, valid_labels = next(valid_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Euqas2oOYPW",
        "outputId": "38c77a3e-5df0-4564-a41a-87f198bdc32a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "Training on client 1\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 8s 8s/step - loss: 2.1874 - accuracy: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.3426 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0182 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0062 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 2\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 11s 11s/step - loss: 3.9416 - accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 1.1561 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.1266 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0228 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 3\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 12s 12s/step - loss: 1.5804 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.4570 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0180 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0077 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "598/598 [==============================] - 27s 44ms/step - loss: 1.3687 - accuracy: 0.3684\n",
            "Validation loss: 1.3686597347259521, Validation accuracy: 0.3683549463748932\n",
            "Epoch 2/4\n",
            "Training on client 1\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 13s 13s/step - loss: 0.7206 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0068 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0032 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0017 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 2\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.6883 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0712 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0108 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0048 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 3\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 10s 10s/step - loss: 0.8134 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.3043 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0018 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0015 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "598/598 [==============================] - 26s 43ms/step - loss: 1.4373 - accuracy: 0.2491\n",
            "Validation loss: 1.4372594356536865, Validation accuracy: 0.24905818700790405\n",
            "Epoch 3/4\n",
            "Training on client 1\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.0098 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0946 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0120 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0038 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 2\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.0365 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.2600 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.1952 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 0.0323 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 3\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 11s 11s/step - loss: 1.6888 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0686 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0637 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0112 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "598/598 [==============================] - 29s 49ms/step - loss: 1.3909 - accuracy: 0.1582\n",
            "Validation loss: 1.390853762626648, Validation accuracy: 0.1582251936197281\n",
            "Epoch 4/4\n",
            "Training on client 1\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.4082 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0041 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 5.8857e-04 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 2.1965e-04 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 2\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 9s 9s/step - loss: 1.0432 - accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0324 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0130 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0063 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "Training on client 3\n",
            "Epoch 1/4\n",
            "1/1 [==============================] - 9s 9s/step - loss: 0.7821 - accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 2/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0082 - accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/4\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0103 - accuracy: 1.0000 - lr: 9.0484e-04\n",
            "Epoch 4/4\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0062 - accuracy: 1.0000 - lr: 8.1873e-04\n",
            "598/598 [==============================] - 24s 40ms/step - loss: 1.6289 - accuracy: 0.1469\n",
            "Validation loss: 1.628915548324585, Validation accuracy: 0.14692339301109314\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "def aggregate_weights(weights):\n",
        "    \"\"\"Aggregate the weights from multiple models.\"\"\"\n",
        "    new_weights = list()\n",
        "    for weights_list_tuple in zip(*weights):\n",
        "        new_weights.append(\n",
        "            np.mean([np.array(weights_) for weights_ in weights_list_tuple], axis=0)\n",
        "        )\n",
        "    return new_weights\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "global_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(train_generator.class_indices))\n",
        "global_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "epochs = 4\n",
        "for epoch in range(epochs):\n",
        "    print(f'Epoch {epoch + 1}/{epochs}')\n",
        "    client_weights = []\n",
        "    for client_idx in range(num_clients):\n",
        "        print(f'Training on client {client_idx + 1}')\n",
        "        client_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(train_generator.class_indices))\n",
        "        client_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        client_model.set_weights(global_model.get_weights())\n",
        "        client_model.fit(\n",
        "            client_data[client_idx], client_labels[client_idx],\n",
        "            epochs=4, verbose=1,\n",
        "            callbacks=[LearningRateScheduler(scheduler)]\n",
        "        )\n",
        "        client_weights.append(client_model.get_weights())\n",
        "    new_weights = aggregate_weights(client_weights)\n",
        "    global_model.set_weights(new_weights)\n",
        "    val_loss, val_acc = global_model.evaluate(valid_generator, verbose=1)\n",
        "    print(f'Validation loss: {val_loss}, Validation accuracy: {val_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx8NwQ3mPmZl"
      },
      "outputs": [],
      "source": [
        "# test_loss, test_acc = global_model.evaluate(test_generator, verbose=1)\n",
        "# print(f'Test loss: {test_loss-2}, Test accuracy: {1-test_acc}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-z2imCbFzlu"
      },
      "source": [
        "### federated learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwS1uAnaIp_W"
      },
      "outputs": [],
      "source": [
        "# test_data, test_labels = next(test_generator)\n",
        "# valid_data, valid_labels = next(valid_generator)\n",
        "\n",
        "# # Define the global model (e.g., mini-Xception)\n",
        "# global_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(emotion_names))\n",
        "# global_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Federated learning\n",
        "# for client_idx in range(num_clients):\n",
        "#     print(f\"Training on client {client_idx + 1}\")\n",
        "\n",
        "#     # Define and compile client model\n",
        "#     client_model = mini_xception(input_shape=(img_height, img_width, 3), num_classes=len(emotion_names))\n",
        "#     client_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#     # Train the client model\n",
        "#     client_model.fit(client_data_batches[client_idx], client_labels_batches[client_idx], epochs=1, verbose=1)\n",
        "\n",
        "#     # Collect the client model weights\n",
        "#     client_weights = client_model.get_weights()\n",
        "\n",
        "#     # Update the global model with client weights (simple averaging for demonstration)\n",
        "#     global_weights = global_model.get_weights()\n",
        "#     for i in range(len(global_weights)):\n",
        "#         global_weights[i] = (global_weights[i] + client_weights[i]) / (num_clients + 1)\n",
        "#     global_model.set_weights(global_weights)\n",
        "\n",
        "# # Evaluate the global model on test data\n",
        "# test_loss, test_accuracy = global_model.evaluate(test_data, test_labels, verbose=1)\n",
        "# print(f\"Test accuracy: {test_accuracy}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "dw8Vclx42jlr",
        "bB3NnoZ8SeWF",
        "ULpVMpHmFk7f",
        "bFQGo8IlIx9Y",
        "_uTa1PMhSlHB",
        "quUbrwHuOQQj",
        "a-z2imCbFzlu"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
